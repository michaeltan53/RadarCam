{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee1bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from gan_networks import define_G\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59797ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __transforms2pil_resize(method):\n",
    "    mapper = {transforms.InterpolationMode.BILINEAR: Image.BILINEAR,\n",
    "              transforms.InterpolationMode.BICUBIC: Image.BICUBIC,\n",
    "              transforms.InterpolationMode.NEAREST: Image.NEAREST,\n",
    "              transforms.InterpolationMode.LANCZOS: Image.LANCZOS,}\n",
    "    return mapper[method]\n",
    "\n",
    "def __scale_width(img, target_size, crop_size, method=transforms.InterpolationMode.BICUBIC):\n",
    "    method = __transforms2pil_resize(method)\n",
    "    ow, oh = img.size\n",
    "    if ow == target_size and oh >= crop_size:\n",
    "        return img\n",
    "    w = target_size\n",
    "    h = int(max(target_size * oh / ow, crop_size))\n",
    "    return img.resize((w, h), method)\n",
    "\n",
    "def get_transform(load_size, crop_size, method=transforms.InterpolationMode.BICUBIC):\n",
    "    transform_list = [transforms.Lambda(lambda img: __scale_width(img, load_size, crop_size, method)),\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    return transforms.Compose(transform_list)\n",
    "\n",
    "def tensor2im(input_image, imtype=np.uint8):\n",
    "    \"\"\"\"Converts a Tensor array into a numpy image array.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (tensor) --  the input image tensor array\n",
    "        imtype (type)        --  the desired type of the converted numpy array\n",
    "    \"\"\"\n",
    "    if not isinstance(input_image, np.ndarray):\n",
    "        if isinstance(input_image, torch.Tensor):  # get the data from a variable\n",
    "            image_tensor = input_image.data\n",
    "        else:\n",
    "            return input_image\n",
    "        image_numpy = image_tensor[0].cpu().float().numpy()  # convert it into a numpy array\n",
    "        if image_numpy.shape[0] == 1:  # grayscale to RGB\n",
    "            image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
    "        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0  # post-processing: tranpose and scaling\n",
    "    else:  # if it is a numpy array, do nothing\n",
    "        image_numpy = input_image\n",
    "    return image_numpy.astype(imtype)\n",
    "\n",
    "\n",
    "del create_model_and_transform(pretrained:str=None):\n",
    "    # Creating model\n",
    "    input_nc = 3\n",
    "    output_nc = 3\n",
    "    ngf = 64\n",
    "    netG = 'resnet_9blocks'\n",
    "    norm = 'instance'\n",
    "    no_dropout = True\n",
    "    init_type = 'normal'\n",
    "    init_gain = 0.02\n",
    "    gpu_ids = []\n",
    "    \n",
    "    netG_A = networks.define_G(input_nc, output_nc, ngf, netG, norm, not no_dropout, init_type, init_gain, gpu_ids)\n",
    "    if pretrained:\n",
    "        chkpntA = torch.load(pretrained)\n",
    "        netG_A.load_state_dict(chkpntA)\n",
    "    netG_A.eval()\n",
    "    \n",
    "    # Creating transform\n",
    "    load_size = 1280\n",
    "    crop_size = 224\n",
    "    image_transforms = get_transform(load_size=load_size, crop_size=crop_size)\n",
    "    return netG_A, image_transforms\n",
    "        \n",
    "\n",
    "def run_inference(img_path, model, transform):\n",
    "    image = Image.open(img_path)\n",
    "    inputs = image_transforms(image).unsqueeze(0)#.to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = model(inputs)\n",
    "    out = tensor2im(out)\n",
    "    return Image.fromarray(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc20d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan, image_transforms = create_model_and_transform(pret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ebf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.listdir(\"gan_images/\")\n",
    "save_folder = \"gan/\"\n",
    "\n",
    "for img in tqdm(image_path):\n",
    "    trg = os.path.join(\"gan_images/\", img)\n",
    "    src = os.path.join(f\"gan/\", img.split('.')[0]+\"-sgan.jpg\")\n",
    "    if not (os.path.exists(src)):\n",
    "        out = run_inference(img_path=trg, model=gan, transform=image_transforms)\n",
    "        out.save(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1105c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = run_inference(img_path=\"datasets/test/0a0c3694-487a156f.jpg\", model=gan, transform=image_transforms)\n",
    "out.save(\"out2.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
